{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09343fe-8c94-49a8-b5ef-4da8e6793486",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/iteso.jpg' width=\"100\" height=\"200\"/></a>\n",
    "\n",
    "# <center> <font color= #000047>Escalamiento de Variables Numéricas </font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87579130",
   "metadata": {},
   "source": [
    "El **escalamiento de variables numéricas** es una etapa fundamental en el preprocesamiento de datos para machine learning y análisis estadístico. Consiste en transformar los valores de las variables numéricas para que tengan una escala comparable, lo que mejora el desempeño de muchos algoritmos.\n",
    "\n",
    "A continuación se explican las principales técnicas de escalamiento, cada una con ejemplos prácticos en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a0489",
   "metadata": {},
   "source": [
    "## 1. Estandarización (Standardization)\n",
    "\n",
    "La estandarización transforma los datos para que tengan media cero y desviación estándar uno. Es útil cuando los datos tienen una distribución aproximadamente normal.\n",
    "\n",
    "La fórmula es:\n",
    "\n",
    "$$ X_{est} = \\frac{X - \\mu}{\\sigma} $$\n",
    "\n",
    "donde $\\mu$ es la media y $\\sigma$ la desviación estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de estandarización con sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = {'A': [10, 20, 30, 40, 50], 'B': [100, 150, 200, 250, 300]}\n",
    "df = pd.DataFrame(data)\n",
    "scaler = StandardScaler()\n",
    "df_std = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e68ab-c7cd-4ee6-bb51-cea20dce284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd412897-0103-4054-9837-be2c99fa69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización manual\n",
    "df_manual = (df - df.mean()) / df.std()\n",
    "print(df_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2946cf9-bc95-46f9-9741-b57d8247cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otro ejemplo\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()\n",
    "df_california = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_california_std = pd.DataFrame(scaler.fit_transform(df_california), columns=df_california.columns)\n",
    "df_california_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b9e1d-7f59-431c-afae-3e9ae2a91785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af7b8e-57ae-4a80-b91f-2e146208527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california_std.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3caf166-752d-4937-87af-4ec38f23f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Media\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9d49d-2795-4bd2-8ad7-173593191ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desviación estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f4f22-a66f-4af5-830d-bb943ab0a7c5",
   "metadata": {},
   "source": [
    "**Ventajas:**\n",
    "- Útil para algoritmos que asumen datos centrados y con varianza unitaria (regresión lineal, SVM, PCA, redes neuronales).\n",
    "- No está acotada a un rango específico, por lo que no distorsiona outliers.\n",
    "\n",
    "**Desventajas:**\n",
    "- No garantiza un rango fijo.\n",
    "- Puede verse afectada por outliers.\n",
    "\n",
    "se recomienda utilizar esta metodología cuando:\n",
    "- Los datos tienen distribución aproximadamente normal.\n",
    "- Cuando se usan algoritmos sensibles a la escala pero no al rango.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b86f0",
   "metadata": {},
   "source": [
    "## 2. Normalización basada en la media (Mean Normalization)\n",
    "\n",
    "Esta técnica centra los datos en torno a cero, escalando según el rango:\n",
    "\n",
    "$$ X_{norm} = \\frac{X - \\mu}{X_{max} - X_{min}} $$\n",
    "\n",
    "Es útil cuando se quiere que los datos estén entre -1 y 1 (aproximadamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0114b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización basada en la media (manual)\n",
    "df_mean_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "print(df_mean_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604be65-d047-4eb3-9277-368c3e5f531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()\n",
    "df_cal = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "df_cal_mean_norm = (df_cal - df_cal.mean()) / (df_cal.max() - df_cal.min())\n",
    "df_cal_mean_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4612c4d9-d04c-478b-bd4b-5230439b138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal_mean_norm['MedInc'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25574e-97ba-44dc-a42a-cface0acdf2b",
   "metadata": {},
   "source": [
    "**Ventajas:**\n",
    "- Centra los datos en cero y los escala en función del rango.\n",
    "- Útil para algoritmos que requieren datos centrados y acotados.\n",
    "\n",
    "**Desventajas:**\n",
    "- Sensible a outliers.\n",
    "- Menos común en librerías estándar.\n",
    "\n",
    "esta técnica se utliza cuand se requiere centrado y escala acotada, pero no necesariamente [0,1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc9d9e",
   "metadata": {},
   "source": [
    "## 3. Escalamiento de valores máximo y mínimo (Min-Max Scaling)\n",
    "\n",
    "Transforma los datos para que estén en un rango específico, típicamente [0, 1]:\n",
    "\n",
    "$$ X_{minmax} = \\frac{X - X_{min}}{X_{max} - X_{min}} $$\n",
    "\n",
    "Es muy útil cuando se requiere que los datos estén en un rango fijo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04418dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamiento Min-Max con sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamiento Min-Max manual\n",
    "df_minmax_manual = (df - df.min()) / (df.max() - df.min())\n",
    "df_minmax_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da39da-c5f3-46aa-be5c-a8f27867bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otro ejemplo\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "df_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "scaler = MinMaxScaler()\n",
    "df_diabetes_minmax = pd.DataFrame(scaler.fit_transform(df_diabetes), columns=df_diabetes.columns)\n",
    "df_diabetes_minmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60962f1e-b23c-44a5-aa30-ad642e339681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes_minmax.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95d02f-9034-47dc-a1e8-7d92ec4a6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes_minmax.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495b688-6bb1-422b-ad78-cd8537a8bcd5",
   "metadata": {},
   "source": [
    "**Ventajas:**\n",
    "- Escala los datos a un rango definido, normalmente [0,1].\n",
    "- Útil para algoritmos basados en distancias (KNN, redes neuronales, clustering).\n",
    "\n",
    "**Desventajas:**\n",
    "- Muy sensible a outliers: un solo valor extremo puede distorsionar la escala.\n",
    "\n",
    "es recomendable usar esta técnica cuando:\n",
    "- Se requiere un rango fijo.\n",
    "- Cuando los datos no tienen outliers significativos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5be3e2",
   "metadata": {},
   "source": [
    "## 4. Escalamiento de máximo absoluto (MaxAbs Scaling)\n",
    "\n",
    "Escala los datos dividiendo por el valor absoluto máximo de cada variable, útil para datos centrados en cero o con valores positivos y negativos:\n",
    "\n",
    "$$ X_{maxabs} = \\frac{X}{|X_{max}|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3408b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con valores negativos\n",
    "df2 = pd.DataFrame({'A': [-1, 0, 1, 2], 'B': [-10, 0, 10, 20]})\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "df_maxabs = pd.DataFrame(scaler.fit_transform(df2), columns=df2.columns)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b7c7c-178f-4fe7-8592-13a0568b5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamiento MaxAbs manual\n",
    "df_maxabs_manual = df2 / df2.abs().max()\n",
    "df_maxabs_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87abb3e-3beb-4b07-87cb-84bedec72f1e",
   "metadata": {},
   "source": [
    "**Ventajas:**\n",
    "- Preserva la dispersión de los datos centrados en cero.\n",
    "- No desplaza los datos (no centra en cero).\n",
    "- Útil para datos dispersos (sparse data).\n",
    "\n",
    "**Desventajas:**\n",
    "- Sensible a valores extremos.\n",
    "- No centra los datos.\n",
    "\n",
    "Se utiliza cuando:\n",
    "- Los datos ya están centrados en cero o contienen valores negativos y positivos.\n",
    "- Se trabaja con datos dispersos (por ejemplo, texto vectorizado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72b299",
   "metadata": {},
   "source": [
    "## 5. Escalamiento por cuantiles (Quantile Transformer)\n",
    "\n",
    "Esta técnica transforma la distribución de los datos para que siga una distribución uniforme o normal, usando los cuantiles de los datos.\n",
    "\n",
    "Es útil para variables con outliers o distribuciones no normales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e2610-7156-48a5-8a70-5930faa6f5f9",
   "metadata": {},
   "source": [
    "$$z = \\frac{X - \\bar{X}}{Q_3 - Q_1}$$\n",
    "\n",
    "donde $\\bar{X}$ es la mediana de $X$ y $Q_1$, $Q_3$ corresponden a los cuartiles uno y tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4638c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamiento por cuantiles a distribución uniforme\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "qt = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
    "df_quantile = pd.DataFrame(qt.fit_transform(df), columns=df.columns)\n",
    "df_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e48d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamiento por cuantiles a distribución normal\n",
    "qt_norm = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "df_quantile_norm = pd.DataFrame(qt_norm.fit_transform(df), columns=df.columns)\n",
    "df_quantile_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b4f5b8-9a0b-4e09-ad00-938bb858f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()\n",
    "df_cal = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "qt = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "df_cal_quantile = pd.DataFrame(qt.fit_transform(df_cal), columns=df_cal.columns)\n",
    "print(df_cal_quantile.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98301b15-6525-46e1-891c-f9ddc710baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6460e63-dd72-4e3b-852a-386ff354e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal_quantile.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00692ac-a96c-4f65-9d2e-61549dedb8d4",
   "metadata": {},
   "source": [
    "**Ventajas:**\n",
    "- Reduce el efecto de outliers.\n",
    "- Puede transformar la distribución a uniforme o normal.\n",
    "- Útil para algoritmos que asumen normalidad o para robustecer frente a valores extremos.\n",
    "\n",
    "**Desventajas:**\n",
    "- Puede distorsionar relaciones lineales entre variables.\n",
    "- Más costoso computacionalmente.\n",
    "\n",
    "Es recomendable usar escalamiento por cuantiles cuando:\n",
    "- Los datos tienen outliers o distribuciones no normales.\n",
    "- Cuando se requiere una distribución específica (normal o uniforme).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9cdda",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "- **Estandarización:** Media 0, desviación estándar 1.\n",
    "- **Normalización basada en la media:** Centrado en 0, escala [-1, 1].\n",
    "- **Min-Max:** Rango [0, 1] (o personalizado).\n",
    "- **MaxAbs:** Rango [-1, 1] según el valor absoluto máximo.\n",
    "- **Cuantiles:** Distribución uniforme o normal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96097787-84d0-473f-ad7f-ed6f157d061c",
   "metadata": {},
   "source": [
    "| Técnica                | Ventajas principales                          | Desventajas principales         | Usos recomendados                           |\n",
    "|------------------------|-----------------------------------------------|---------------------------------|---------------------------------------------|\n",
    "| Estandarización        | Media 0, varianza 1, útil para normalidad     | No acota rango, sensible a outliers | Regresión, SVM, PCA, redes neuronales      |\n",
    "| Normalización media    | Centra y acota, fácil de interpretar          | Sensible a outliers             | Datos centrados y acotados                  |\n",
    "| Min-Max                | Rango fijo, fácil de interpretar              | Muy sensible a outliers         | KNN, clustering, redes neuronales           |\n",
    "| MaxAbs                 | Preserva dispersión, útil para datos dispersos| No centra, sensible a outliers  | Datos dispersos, texto vectorizado          |\n",
    "| Cuantiles              | Robusto a outliers, ajusta distribución       | Distorsiona relaciones lineales | Datos con outliers, requiere normalidad     |\n",
    "\n",
    "La elección depende del algoritmo y la naturaleza de los datos. Siempre analiza la distribución y presencia de outliers antes de elegir el método de escalamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08186d76-4abf-4cfa-9ad2-1a662e8e916e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
